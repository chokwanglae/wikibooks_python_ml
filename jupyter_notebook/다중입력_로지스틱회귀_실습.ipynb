{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 입력 로지스틱 회귀 모델\n",
    "2개의 입력을 받아 0 또는 1을 출력하는 로지스틱 회귀 모델을 케라스로 구현해보도록 하겠습니다.  \n",
    "2개의 입력을 받아 1개의 출력을 내는 예제로는 대표적으로 AND 연산이 있습니다.  \n",
    "AND 연산 로지스틱 회귀를 케라스로 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid(w1x1 + w2x2 + b)의 형태를 갖는 간단한 로지스틱 회귀를 케라스로 구현합니다.  \n",
    "첫번째 Dense는 선형회귀 레이어입니다.  \n",
    "input_dim=2은 입력값이 2개를 의미하며, units = 1은 출력값이 1개임을 의미합니다.  \n",
    "선형 회귀에 이어서 로지스틱(시그모이드) 함수를 붙여서, 선형회귀의 출력값을 0부터 1의 값으로 정규화합니다.  \n",
    "학습 과정 시, 경사하강법(sgd)을 사용하여 cross entropy를 최소화하는 W(w1, w2)와 b를 찾습니다. \n",
    "binary_accuracy는 모델의 출력값이 0.5 이상일 경우는 출력값을 1로 판단하고,  \n",
    "0.5 이하일 경우 0으로 판단하여, y값과 비교하여, 모델의 정확도를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=2, units = 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습시키기 위한 데이터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([(0,0), (0,1), (1,0), (1,1)]) \n",
    "Y = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습을 진행합니다.  \n",
    "5000번의 반복 학습을 통해, 최적의 w1, w2, b를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10dcbb8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=5000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터에 따른 실제 모델의 출력값을 확인해봅니다.  \n",
    "(0,0), (0,1), (1,0)에 해당하는 값은 0.5보다 작고, (1,1)은 0.5보다 큰 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03217257],\n",
       "       [0.223704  ],\n",
       "       [0.20164248],\n",
       "       [0.6864704 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 model.summary() 명령어를 사용하여, 모델의 구성이 어떻게 이뤄졌는 지 확인합니다.  \n",
    "우리의 다중 입력 로지스틱 모델은 w1, w2, b가 첫번째 레이어에 존재하며, 학습 과정을 통해  \n",
    "최적의 W(w1, w2)와 b값이 지정됩니다.\n",
    "dense_1 레이어에 3개의 param이 있는 것을 확인하실 수 있으며, 이 3개의 param이 w1, w2, b입니다.\n",
    "dense_1 레이어를 선형 회귀 레이어라고 보실 수 있습니다.  \n",
    "선형 회귀 레이어의 출력값은 activation_1 레이어의 입력값으로 들어갑니다.  \n",
    "activation_1 레이어는 시그모이드 함수로 우리가 설정했으며, 특별히 학습되는 param은 존재하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 레이어에 존재하는 w1, w2, b는 아래의 명령어로 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(2, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 통해 얻어진 최적의 w1, w2, b는 get_weights() 함수로 확인 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.0278792],\n",
       "        [2.1597292]], dtype=float32), array([-3.4039395], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
